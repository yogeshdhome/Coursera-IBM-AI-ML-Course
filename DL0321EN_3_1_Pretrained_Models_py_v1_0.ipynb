{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "DL0321EN-3-1-Pretrained-Models-py-v1.0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogeshdhome/Coursera-IBM-AI-ML-Course/blob/master/DL0321EN_3_1_Pretrained_Models_py_v1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "YoyIXP6l3-Oo"
      },
      "source": [
        "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
        "\n",
        "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "8dx2t95d3-Oq"
      },
      "source": [
        "## Objective\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "pp1dIYaD3-Or"
      },
      "source": [
        "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "1v0T49303-Os"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3> \n",
        "    \n",
        "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
        "2. <a href=\"#item32\">Download Data</a>  \n",
        "3. <a href=\"#item33\">Define Global Constants</a>  \n",
        "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
        "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
        "\n",
        "</font>\n",
        "    \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "spAXDjXY3-Os"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Z3JNyK-V3-Ot"
      },
      "source": [
        "<a id='item31'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "IgIMHEBm3-Ot"
      },
      "source": [
        "## Import Libraries and Packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Uueqz8QS3-Ou"
      },
      "source": [
        "Let's start the lab by importing the libraries that we will be using in this lab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "BvMe8OvD3-Ou"
      },
      "source": [
        "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "vW9hQIyU3-Ov"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Mpn5sL0H3-Ow"
      },
      "source": [
        "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "G3guKSZt3-Ox"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "eFi5ofwN3-Ox"
      },
      "source": [
        "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "ekLfLID13-Ox"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "8ugaTP-23-Oy"
      },
      "source": [
        "<a id='item32'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "f8SwkeK83-Oy"
      },
      "source": [
        "## Download Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "vxd6CKlZ3-Oy"
      },
      "source": [
        "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "sS0Yc3zw3-Oy"
      },
      "source": [
        "## get the data\n",
        "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "D49kh2mP3-Oz"
      },
      "source": [
        "And now if you check the left directory pane, you should see the zipped file _concrete_data_week3.zip_ appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "scrolled": true,
        "tags": [],
        "id": "5PVJiJve3-Oz"
      },
      "source": [
        "#!unzip concrete_data_week3.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbwCv9AX4rND"
      },
      "source": [
        "import requests, zipfile, io\n",
        "url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip'\n",
        "\n",
        "r = requests.get(url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall(\"/content/\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvhy6hI43-O0",
        "outputId": "90bf1941-d888-494d-9476-04c7ac7b04ed"
      },
      "source": [
        "import os\n",
        "len(os.listdir('concrete_data_week3/train/positive'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "yCe_sg973-O0"
      },
      "source": [
        "Now, you should see the folder _concrete_data_week3_ appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: _train_ and _valid_. And if you explore these folders, you will find that each contains two subfolders: _positive_ and _negative_. These are the same folders that we saw in the labs in the previous modules of this course, where _negative_ is the negative class and it represents the concrete images with no cracks and _positive_ is the positive class and it represents the concrete images with cracks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "jwE_CHiO3-O1"
      },
      "source": [
        "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the _negative_ and _positive_ folders. This may consume all of your memory and you may end up with a **50\\*** error. So please **DO NOT DO IT**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "4NsOan-63-O1"
      },
      "source": [
        "<a id='item33'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "BKW8Qb5Z3-O1"
      },
      "source": [
        "## Define Global Constants\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "vOpBVK5x3-O1"
      },
      "source": [
        "Here, we will define constants that we will be using throughout the rest of the lab. \n",
        "\n",
        "1.  We are obviously dealing with two classes, so _num_classes_ is 2. \n",
        "2.  The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
        "3.  We will training and validating the model using batches of 100 images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "gwCaXFK23-O2"
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "image_resize = 224\n",
        "\n",
        "batch_size_training = 100\n",
        "batch_size_validation = 100"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "oRsvQY_U3-O2"
      },
      "source": [
        "<a id='item34'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "N9At-8_B3-O2"
      },
      "source": [
        "## Construct ImageDataGenerator Instances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Rf1hloOq3-O2"
      },
      "source": [
        "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to _preprocess_input_ which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "jgTi5buQ3-O2"
      },
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "2i578tW13-O3"
      },
      "source": [
        "Next, we will use the _flow_from_directory_ method to get the training images as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xebvWsws3-O3",
        "outputId": "1f1cac48-f762-485e-ebdd-6d5343e94ab7"
      },
      "source": [
        "train_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/train',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_training,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30001 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "jmCALrzc3-O4"
      },
      "source": [
        "**Your Turn**: Use the _flow_from_directory_ method to get the validation images and assign the result to **validation_generator**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYFxIw0a3-O4",
        "outputId": "9fa17427-fb62-40ee-918e-d262a8ae7353"
      },
      "source": [
        "## Type your answer here\n",
        "\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size = (image_resize, image_resize),\n",
        "    batch_size = batch_size_validation,\n",
        "    class_mode = 'categorical')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10001 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "He-gCfgj3-O5"
      },
      "source": [
        "Double-click **here** for the solution.\n",
        "\n",
        "<!-- The correct answer is:\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical')\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "kikznq3g3-O5"
      },
      "source": [
        "<a id='item35'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Dxss4z5_3-O5"
      },
      "source": [
        "## Build, Compile and Fit Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "YHgaAKCs3-O5"
      },
      "source": [
        "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "2UcvAIBI3-O5"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "-XQmUYk83-O6"
      },
      "source": [
        "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument _include_top_ and set it to **False**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kngmGGFt3-O6",
        "outputId": "2200e2b7-df56-4558-e5f3-cfe94ce0e4c6"
      },
      "source": [
        "model.add(ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet',\n",
        "    ))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "0IGyVYvD3-O_"
      },
      "source": [
        "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "BtUfJEDS3-PA"
      },
      "source": [
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "JHPc7lG63-PA"
      },
      "source": [
        "You can access the model's layers using the _layers_ attribute of our model object. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBShv4r93-PA",
        "outputId": "ac32a36c-c283-4761-f020-484b855fcd5f"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.functional.Functional at 0x7fcf911c26d0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fcf90ffb750>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Dr3PBpSG3-PA"
      },
      "source": [
        "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "NF1RbquX3-PA"
      },
      "source": [
        "You can access the ResNet50 layers by running the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvLBoVsM3-PB",
        "outputId": "6f8848f1-9f49-4d99-8104-e6639cfbd97a"
      },
      "source": [
        "model.layers[0].layers"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fcfa8171910>,\n",
              " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7fcf9bdf2610>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bdf2750>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bc10e50>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d06b750>,\n",
              " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7fcf9d06bd90>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fcf9d031ed0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d04e050>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d048610>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d058210>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d05cb90>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d06b310>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9cfe76d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d03bc90>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d0611d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d040a90>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9cff1050>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9cfe7890>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d044890>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d040810>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d031490>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d06b850>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d05c490>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9cff8e90>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d048d50>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d06b6d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d004f50>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9d001090>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d00b450>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d01a3d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d06b650>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d048c10>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d01dc50>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9cfae590>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9cfa5d50>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d022f10>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9cfc0050>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9cfb2d90>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d0227d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9cfc7fd0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9cfd8390>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9cfd5990>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9cfe0590>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf54350>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bf5d190>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9cfcf050>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf5d9d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9cfcfe90>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf63ed0>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9bf70050>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d06b3d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf778d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf7cc10>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bf87390>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf774d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf100d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bf19210>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf7f990>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcfa1e95790>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9bf5dcd0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9cfd8ed0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf4d850>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9cfd5910>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9cfb2050>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9cfbcd50>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d01d890>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d040b10>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf1f7d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf22890>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9bf29290>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bf249d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf22310>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf32650>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bf3e4d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf224d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf43a90>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bed0990>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf46bd0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bed16d0>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9bee40d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9beda810>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bef8310>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bef2f10>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bf00290>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bf04f10>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf004d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be8d5d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bed1350>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be8a650>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9beed490>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be9dc50>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9be9d490>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be9af90>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bead250>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bead8d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be8acd0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9beb5450>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9beb7dd0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9beadcd0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9beb3350>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bee8090>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9bf32190>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bf43f90>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9cffd110>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf29c90>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9bf22a50>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9cfca250>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9bf6cf90>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9becb690>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9bed1990>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d377b90>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9bebf350>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9d373bd0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be5a190>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be5add0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be51850>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be53410>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be65bd0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be5ead0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be65710>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be6c990>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9be70890>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be79e90>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be80f90>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be87490>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be7df90>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be0c310>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be1d1d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be7db90>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be16c90>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be29810>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9be20890>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be23c90>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be38c50>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be3ef90>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be36c50>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be38a50>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf912222d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be36d50>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be38250>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9be1d550>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9be29d10>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9be2f1d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9be5f890>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9beed0d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9122c390>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9122c850>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9122fad0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf91234050>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9d3730d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf91234490>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9d040dd0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9123f710>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf9123fcd0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf91248a10>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf91254190>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf912564d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf911e1350>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf911e1dd0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf911e5950>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf911ef790>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf911efa90>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf911f8590>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf911f8b50>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf911fd6d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf911ef390>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9120f310>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf9121b1d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf9121ba90>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf9119d7d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf911a9610>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcf911a9550>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf911b4410>,\n",
              " <tensorflow.python.keras.layers.merge.Add at 0x7fcf911b49d0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7fcf911bdb10>,\n",
              " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7fcf9bf63a10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "l9SiVxFb3-PB"
      },
      "source": [
        "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "L8kJL7003-PB"
      },
      "source": [
        "model.layers[0].trainable = False"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "pF0ov_LH3-PC"
      },
      "source": [
        "And now using the _summary_ attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouSG5YOU3-PC",
        "outputId": "5d00bf0b-f7a8-4d2b-81be-d82cb700f3f4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 23,591,810\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "X7T2ivvu3-PC"
      },
      "source": [
        "Next we compile our model using the **adam** optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "n946DGTc3-PC"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "NTuSM7tR3-PD"
      },
      "source": [
        "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "id": "KHg9sWTK3-PD"
      },
      "source": [
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "num_epochs = 2"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "LSf8iRJQ3-PD"
      },
      "source": [
        "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7YvK68b3-PD",
        "outputId": "19d6bd18-69c9-41b9-c9df-11e2afb9b94a"
      },
      "source": [
        "fit_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "301/301 [==============================] - 165s 436ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 2/2\n",
            "301/301 [==============================] - 133s 442ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0045 - val_accuracy: 0.9989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "s0kIdNwc3-PD"
      },
      "source": [
        "Now that the model is trained, you are ready to start using it to classify images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "B1JtA-9w3-PE"
      },
      "source": [
        "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J3PxYTs3-PE",
        "outputId": "872e037b-3281-4e5f-bcb3-1d062fd9be1e"
      },
      "source": [
        "model.save('/content/classifier_resnet_model.h5')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "ZwwSv2ij3-PE"
      },
      "source": [
        "Now, you should see the model file _classifier_resnet_model.h5_ apprear in the left directory pane.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "mUMuKV1s3-PE"
      },
      "source": [
        "### Thank you for completing this lab!\n",
        "\n",
        "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "eJNDS2kc3-PE"
      },
      "source": [
        "This notebook is part of a course on **Coursera** called _AI Capstone Project with Deep Learning_. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7n12FGK3-PE"
      },
      "source": [
        "## Change Log\n",
        "\n",
        "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
        "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
        "| 2020-09-18        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "jh2A0-cg3-PF"
      },
      "source": [
        "<hr>\n",
        "\n",
        "Copyright  2020 [IBM Developer Skills Network](https://cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork-20647850&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
      ]
    }
  ]
}